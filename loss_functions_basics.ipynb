{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sztuczne sieci neuronowe - laboratorium 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dane studenta: Natalia Chostenko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytania kontrolne\n",
    "\n",
    "1. Jakie znasz funkcje straty (w regresji i w klasyfikacji)?\n",
    "2. Jakie znasz algorytmy (min. jeden, wraz z wariantami) minimalizacji funkcji straty?\n",
    "3. Czym jest gradient funkcji?\n",
    "4. Wymień znane Ci hiperparametry stosowane w algorytmie najszybszego spadku.\n",
    "5. Jakie problemy mogą wystąpić przy nieodpowiednim doborze hiperparametrów tego algorytmu?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przypomnienie poprzedniego ćwiczenia\n",
    "\n",
    "Poprzednie ćwiczenie:\n",
    "> Załóżmy, że mamy dwa termometry:\n",
    "> - jeden mierzy temperaturę w stopniach Celsjusza\n",
    "> - drugi mierzy temperaturę w nieznanej nam skali, ale jest bardzo ładny i chcemy go powiesić na ścianie\n",
    ">\n",
    "> Zanim to zrobimy, chcemy się dowiedzieć, jak przeliczać wskazania drugiego termometru na stopnie Celsjusza.\n",
    "> Spróbujemy znaleźć \"wzór\" tego przekształcenia na podstawie pomiarów dokonanych obydwoma termometrami.\n",
    "\n",
    "W poprzednim ćwiczeniu:\n",
    "- na podstawie wizualizacji danych wybraliśmy do tego problemu model liniowy\n",
    "- zaimplementowaliśmy go jako funkcję `model` (dwa parametry: `w` i `b`)\n",
    "- zdefiniowaliśmy funkcję straty dla regresji liniowej - błąd średniokwadratowy (funkcja `loss_fn`)\n",
    "- na potrzeby obliczenia gradientu funkcji straty (wektora pochodnych względem parametrów modelu, `dL/dw`) zdefiniowailśmy funkcje obliczające poszczególne komponenty reguły łańcuchowej (`dL/dw = (dL/dtp) * (dtp/dw)`)\n",
    "- podjęliśmy próbę minimalizacji funkcji straty algorytmem najszybszego spadku\n",
    "- eksperymentowaliśmy z wartością stałej uczącej (`learning_rate`)\n",
    "- zauważyliśmy konieczność normalizacji danych\n",
    "- na podstawie wyznaczonych wartości parametrów znaleźliśmy przekształcenie ze skali Fahrenheita do skali Celsjusza\n",
    "\n",
    "Dzisiaj dowiemy się, jak niektóre z tych kroków zrealizować \"automatycznie\" z użyciem PyTorch `autograd` i `torch.optim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_unknown = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "data_celsius = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
    "\n",
    "t_u = torch.tensor(data_unknown)\n",
    "t_c = torch.tensor(data_celsius)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(t_u, w, b):\n",
    "    return w * t_u + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c) ** 2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizacja danych\n",
    "\n",
    "W poprzednim ćwiczeniu, aby algorytm najszybszego spadku nie \"wybuchł\", należało znormalizować dane wejściowe. Zgodnie z oryginalnym przykładem z książki \"Deep Learning with PyTorch\" normalizacja polegała na dziesięciokrotnym pomniejszeniu wejść (aby sprowadzić dane do \"bezpieczniejszego\" przedziału). Ta niestandardowa normalizacja wprowadziła jednak nieco niepotrzebnego chaosu do zajęć.\n",
    "\n",
    "Dlatego dzisiaj zrobimy inaczej - poddamy dane wejściowe standaryzacji.\n",
    "\n",
    "\n",
    "#### Ćwiczenie\n",
    "Dokonaj standaryzacji danych wejściowych i przypisz je do tensora `t_un`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.9565,  0.2436,  0.3802,  1.7883,  0.2673, -0.1723, -1.0635, -1.7823,\n",
      "        -0.2020,  0.5109,  0.9862])\n"
     ]
    }
   ],
   "source": [
    "# mean i std\n",
    "t_u_mean = t_u.mean()\n",
    "t_u_std = t_u.std()\n",
    "\n",
    "# standaryzacja\n",
    "t_un = (t_u - t_u_mean) / t_u_std\n",
    "\n",
    "print(t_un)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch autograd\n",
    "\n",
    "W przypadku regresji liniowej dla jednej zmiennej wejściowej i dwóch parametrów, \"ręczne\" obliczenie pochodnych nie było szczególnie uciążliwe. Dla bardziej skomplikowanych modeli (a takimi będą sieci neuronowe) warto użyć narzędzia, które może wykonać tę pracę za nas.\n",
    "\n",
    "`autograd` to wbudowany w PyTorch silnik do obliczania pochodnych funkcji - także złożonych.\n",
    "\n",
    "Poza przechowywaniem wartości liczbowych, tensory w PyTorch mogą zapamiętywać, poprzez jakie operacje i z których (innych) tensorów powstały, tworząc strukturę grafu obliczeń (\"computation graph\"). Na podstawie tego grafu `autograd` może następnie obliczyć pochodne względem poszczególnych parametrów modelu.\n",
    "\n",
    "Wartości pochodnych będą zapisane w atrybucie `.grad` tensora. Aby włączyć działanie `autograd` dla konkretnego tensora (oraz wszystkich tensorów, które z niego powstają w wyniku różnych operacji), należy przy tworzeniu go podać argument `requires_grad=True`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ćwiczenie\n",
    "Stwórz tensor `params` zawierający początkowe wartości parametrów: w = 1 i b = 0. Zadbaj o włączenie `autograd` dla tego tensora. Sprawdź wartość `params.grad` zaraz po utworzeniu tensora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "\n",
    "print(params.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aktualizacja gradientów\n",
    "\n",
    "Zawartość atrybutu `grad` aktualizuje się po wywołaniu funkcji `loss.backward()` (gdzie `loss` to tensor reprezentujący  funkcję straty po przejściu \"w przód\" przez graf).\n",
    "\n",
    "Wyjaśnienie:  \n",
    "Podczas obliczania funkcji straty (gdy dla `params` ustawimy `requires_grad=True`), poza samymi obliczeniami tworzy się graf reprezentujący poszczególne operacje jako wierzchołki (końcowym wierzchołkiem jest `loss`). Po wywołaniu `loss.backward()` graf przetwarzany jest wstecz i obliczane są pochodne względem poszczególnych parametrów.\n",
    "\n",
    "#### Ćwiczenie\n",
    "Użyj przygotowanych funkcji `model` i `loss_fn`, aby stworzyć graf obliczeń i uzyskać tensor reprezentujący funkcję straty, a następnie uruchom na nim metodę `backward()`. Sprawdź wartość `params.grad`. Sprawdź też (np. z użyciem `print`), jaka jest zawartość tensorów funkcji straty i predykcji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gradienty params tensor([-14.6089, -21.0000])\n",
      "funkcja straty tensor(171.8683, grad_fn=<MeanBackward0>)\n",
      "predykcja tensor([-0.9565,  0.2436,  0.3802,  1.7883,  0.2673, -0.1723, -1.0635, -1.7823,\n",
      "        -0.2020,  0.5109,  0.9862], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#predykcja\n",
    "t_p = model(t_un, *params)\n",
    "\n",
    "#funkcja straty\n",
    "loss = loss_fn(t_p, t_c)\n",
    "loss.backward()\n",
    "\n",
    "print(\"gradienty params\", params.grad)\n",
    "print(\"funkcja straty\", loss)\n",
    "print(\"predykcja\", t_p)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Akumulacja gradientów\n",
    "Uwaga:  \n",
    "Ze względów praktycznych (np. ze względu na zastosowanie w przypadku ograniczonej pamięci), każde wywołanie `loss.backward()` powoduje akumulację  gradientów (dodanie nowo obliczonych do już istniejących wartości w `.grad`, a nie nadpisanie). Zwykle pożądanym zachowaniem jest jednak użycie jedynie gradientów z aktualnej iteracji. W tym celu należy \"wyzerować\" gradienty, np. na początku każdej iteracji algorytmu optymalizacji."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ćwiczenie\n",
    "Do wyzerowania gradientów na początku każdej iteracji można użyć funkcji `.zero()`.\n",
    "Wyzeruj gradienty tensora `params`. Pomyśl, jak zabezpieczyć się przed błędem, który może się pojawić w pierwszej iteracji algorytmu optymalizacji.\n",
    "\n",
    "Uwaga:  \n",
    "W PyTorchu obowiązuje konwencja, że funkcje z `_` na końcu nazwy służą do wywoływania operacji \"w miejscu\" (in-place) - nie tworzą kopii tensora / widoku na pamieć, ale zmieniają jej zawartość. W ćwiczeniu użyj wariantu \"in-place\" funkcji zerującej tensor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w pierwszej iteracji gradienty mogą jeszcze nie istniec, co spowoduje bląd, w zwiazku z tym przed wywolaniem .zero_ mozna sprawdzic czy params.grad nie jest None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0.])\n"
     ]
    }
   ],
   "source": [
    "if params.grad is not None:\n",
    "    params.grad.zero_()\n",
    "print(params.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ćwiczenie\n",
    "Korzystając z kodu funkcji `training_loop` z poprzedniego ćwiczenia (przeklejonej poniżej), napisz funkcję `training_loop_autograd`, w której ręczne obliczanie gradientu zastąpi użycie silnika `autograd`.\n",
    "\n",
    "Uwaga:  \n",
    "Krok aktualizacji tensora parametrów należy dodatkowo zamknąć w bloku `with torch.no_grad()`: (aby \"na chwilę\" wyłączyć autograd na potrzeby zmiany zawartości tensora `params`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_iters, learning_rate, params, t_u, t_c):\n",
    "    for iteration in range(1, n_iters+1):\n",
    "        w, b = params\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        grad = grad_fn(t_u, t_c, t_p, w, b)\n",
    "        \n",
    "        # tzw. \"vanilla\" gradient descent        \n",
    "        params = params - learning_rate * grad\n",
    "        \n",
    "        print('After iteration %d, Loss %f' % (iteration, float(loss)))\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_autograd(n_iters, learning_rate, params, t_u, t_c):\n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        # nie rozpakowujemy manualnie paraemtrow\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "\n",
    "        # zerowanie gradientow\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "        \n",
    "        # liczenie gradientow\n",
    "        loss.backward()\n",
    "\n",
    "        # Aktualizacja parametrow bez sledzenia przez autograd\n",
    "        with torch.no_grad():\n",
    "            params -= learning_rate * params.grad\n",
    "\n",
    "        if iteration % 500 == 0:  # zeby nie wypisywac wszystkiego\n",
    "            print('After iteration %d, Loss %f' % (iteration, float(loss)))\n",
    "    \n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ćwiczenie\n",
    "Uruchom `training_loop_autograd` dla 1000 iteracji, ustaw `learning_rate = 5e-3` i jako dane wejściowe podaj znormalizowany tensor `t_un`. Zainicjalizuj parametry tensorem [1,0, 0.0] (włącz dla niego autograd)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After iteration 500, Loss 2.938963\n",
      "After iteration 1000, Loss 2.927647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 9.0340, 10.4995], requires_grad=True)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 5e-3\n",
    "n_iters = 1000\n",
    "\n",
    "\n",
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "trained_params = training_loop_autograd(n_iters, learning_rate, params, t_un, t_c)\n",
    "\n",
    "trained_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ćwiczenie\n",
    "Zapisz równanie transformujące oryginalne dane wejściowe (`t_u`) do stopni Celsjusza (`t_p`).\n",
    "Znajdź współczynniki prostej opisującej model liniowy. Porównaj z wynikiem z poprzednich zajęć.\n",
    "\n",
    "Uwaga / hint:  \n",
    "Uwzględnij średnią i odchylenie standardowe policzone dla danych wejściowych na początku dzisiejszych zajęć."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trzeba przeksztalcic rownanie liniowe do tej postaci:\n",
    "\n",
    "t_p = t_u * w + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5367202758789062 -17.30256462097168\n"
     ]
    }
   ],
   "source": [
    "w, b = params\n",
    "w = w / t_u.std()\n",
    "b = b - w * t_u.mean()\n",
    "print(w.item(),b.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch.optim\n",
    "\n",
    "Algorytm najszybszego spadku jest przykładem jednego z wielu algorytmów optymalizacji dostępnych w PyTorch. Implementacje różnych optymalizatorów znajdują się w module `torch.optim`.\n",
    "\n",
    "Przykłady optymalizatorów w PyTorch:\n",
    "- `SGD` - Stochastic Gradient Descent (tak naprawdę tzw. Batch Gradient Descent), z dodatkową opcją tzw. \"momentum\"\n",
    "- `Adagrad`, `RMSProp` - \"adaptive, per-parameter learning rate\"\n",
    "- `Adam` - Adaptive Moment Estimation - połączenie SGD+momentum z RMSProp - obecnie bardzo popularny\n",
    "- ...\n",
    "\n",
    "Bardziej szczegółowo omówimy te algorytmy w późniejszym czasie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASGD',\n",
       " 'Adadelta',\n",
       " 'Adagrad',\n",
       " 'Adam',\n",
       " 'AdamW',\n",
       " 'Adamax',\n",
       " 'LBFGS',\n",
       " 'NAdam',\n",
       " 'Optimizer',\n",
       " 'RAdam',\n",
       " 'RMSprop',\n",
       " 'Rprop',\n",
       " 'SGD',\n",
       " 'SparseAdam',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_functional',\n",
       " '_multi_tensor',\n",
       " 'lr_scheduler',\n",
       " 'swa_utils']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "dir(optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optymalizacja funkcji straty w torch.optim\n",
    "\n",
    "Optymalizator inicjalizuje się wybierając konkretną klasę z dostępnych w `torch.optim`. Pierwszym argumentem przy tworzeniu optymalizatora jest lista parametrów modelu (nie zawsze wszystkich - czasem np. \"zamraża\" się niektóre parametry i nie aktualizuje ich). Tworząc obiekt optymalizatora podaje się też jako argument m.in. wartość learning rate (argument `lr`).\n",
    "\n",
    "W API optymalizatora są dwie metody: `zero_grad()` oraz `step()`. Pierwsza z nich zeruje gradienty parametrów (patrz wyżej), a druga wykonuje krok aktualizacji parametrów zgodny z wybranym algorytmem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ćwiczenie\n",
    "Zainicjalizuj tensor `params` jako [1.0, 0.0] (z włączonym autograd) oraz optymalizator SGD ze stałą uczącą o wartości 0.01.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.SGD([params], lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ćwiczenie\n",
    "Na podstawie `training_loop_autograd` (napisanej wyżej) napisz funkcję `training_loop_optim`, w której zerowanie gradientów i krok aktualizacji parametrów wykonane będą z użyciem optymalizatora z `torch.optim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop_optim(n_iters, optimizer, params, t_u, t_c):\n",
    "    for iteration in range(1, n_iters + 1):\n",
    "        # nie rozpakowujemy manualnie paraemtrow\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "\n",
    "        # zerowanie gradientow\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # liczenie gradientow\n",
    "        loss.backward()\n",
    "\n",
    "        # krok aktualizacji parametrow z optymalizatorem\n",
    "        optimizer.step()\n",
    "\n",
    "        if iteration % 500 == 0:  # zeby nie wypisywac wszystkiego \n",
    "            print('After iteration %d, Loss %f' % (iteration, float(loss)))\n",
    "    \n",
    "    return params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ćwiczenie\n",
    "Uruchom `training_loop_optim` i porównaj wynik z `training_loop_autograd`. Powinno wyjść to samo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After iteration 500, Loss: 2.9276463985443115\n",
      "After iteration 1000, Loss: 2.9276463985443115\n",
      "tensor([ 9.0340, 10.4995], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "params = training_loop_optim(n_iters, optimizer, params, t_un, t_c)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ćwiczenie\n",
    "Sprawdź, jak w porównaniu do `SGD` poradzi sobie optymalizator `Adam` dla `learning_rate = 0.01` dla nieznormalizowanego (oryginalnego) tensora danych wejściowych `t_u`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After iteration 500, Loss: 25.590320587158203\n",
      "After iteration 1000, Loss: 22.958574295043945\n",
      "tensor([ 0.2700, -2.1840], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 0.0], requires_grad=True)\n",
    "optimizer = optim.Adam([params], lr=0.01)\n",
    "params = training_loop_optim(n_iters, optimizer, params, t_u, t_c)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Podsumowanie:\n",
    "- zamiast obliczać gradienty \"ręcznie\", możemy użyć silnika `autograd`\n",
    "- tensory korzystające z `autograd` (`requires_grad=True`) posiadają atrybut `grad`\n",
    "- wykonywanie operacji na tensorach powoduje tworzenie grafu obliczeń (computation graph)\n",
    "- wywołanie funkcji `loss.backward()` na tensorze reprezentującym funkcję straty powoduje aktualizację gradientów (zmienia się zawartość `.grad` dla tensorów w grafie)\n",
    "- ze względu na akumulację gradientów typowo należy je wyzerować np. na początku każdej iteracji treningu\n",
    "- moduł `torch.optim` zawiera implementacje algorytmów optymalizacji funkcji straty, m.in. SGD, RMSProp, Adam\n",
    "- przy inicjalizacji optymalizatora należy podać jako argument zestaw parametrów modelu do optymalizacji oraz wartość stałej uczącej\n",
    "- korzystając z `torch.optim` w pętli treningowej należy wywołać `optim.zero_grad()` (zerowanie gradientów) oraz `optim.step()` (krok aktualizacji parametrów)\n",
    "\n",
    "Podczas poprzednich i dzisiejszych ćwiczeń poznaliśmy tak naprawdę podstawowy wariant mechanizmu uczenia sieci neuronowych. Sieci neuronowe to po prostu bardziej złożone modele niż model liniowy, posiadają one dużo więcej parametrów i są modelami nieliniowymi. W sieciach neuronowych w PyTorch także tworzy się graf obliczeń na tensorach, który służy następnie do obliczania gradientów funkcji straty z użyciem `autograd`. Krok aktualizacji parametrów wykonuje się typowo z użyciem jednego z dostępnych w `torch.optim` algorytmów."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
